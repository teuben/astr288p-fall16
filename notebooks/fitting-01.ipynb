{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting\n",
    "\n",
    "\n",
    "One of the most common things in scientific computing is model fitting. Numerical Recipes devotes a number of chapters to this.\n",
    "\n",
    "* scipy \"curve_fit\"\n",
    "* astropy.modeling\n",
    "* lmfit (emcee)\n",
    "* pyspeckit\n",
    "\n",
    "We will also need to be able to read data. We will use pickle (-01) and an ascii file reader (-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.mlab as mlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickle\n",
    "you may need to re-visit n6503-case1 and reset **peakpos** in **In[18]** and execute **In[20]** and **In[19]** to get the spectrum file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -l n6503-*.p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "   \n",
    "sp = pickle.load(open(\"n6503-sp.p\",\"rb\"))\n",
    "# print(sp.keys())\n",
    "velz = sp['z']\n",
    "flux = sp['i']\n",
    "plt.plot(velz,flux)\n",
    "plt.xlabel(sp['zunit'])\n",
    "plt.ylabel(sp['iunit'])\n",
    "plt.title(\"Pos: %s %s\" % (str(sp['xpos']),str(sp['ypos'])))\n",
    "#  plt.title(\"Pos: %d %d\" % (sp['xpos'],sp['ypos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute moments of this spectrum to get an idea what the mean and dispersion of this signal is\n",
    "# recall this method can easily result in zdisp < 0 for noisy data\n",
    "tmp1 = flux*velz \n",
    "tmp2 = flux*velz*velz\n",
    "zmean = tmp1.sum()/flux.sum()\n",
    "zdisp = tmp2.sum()/flux.sum() - zmean*zmean\n",
    "\n",
    "print(\"mean,var:\",zmean,zdisp)\n",
    "if zdisp > 0:\n",
    "    sigma = math.sqrt(zdisp)\n",
    "    print(\"sigma,FWHM:\",sigma,sigma*2.355)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the conversion factor from $\\sigma$ to FWHM is $2\\sqrt{2\\ln{2}} \\approx 2.355$, see also\n",
    "https://en.wikipedia.org/wiki/Full_width_at_half_maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# noisy spectra can easily result in bogus values for mean and dispersion. Let's try something else:\n",
    "imax = flux.argmax()\n",
    "print(\"Max at %d: %g %g\" % (imax, velz[imax], flux[imax]))\n",
    "nn = 3\n",
    "flux1 = flux[imax-nn:imax+nn]\n",
    "velz1 = velz[imax-nn:imax+nn]\n",
    "\n",
    "tmp1 = flux1*velz1 \n",
    "tmp2 = flux1*velz1*velz1\n",
    "zmean1 = tmp1.sum()/flux1.sum()\n",
    "zdisp1 = tmp2.sum()/flux1.sum() - zmean1*zmean1\n",
    "\n",
    "print(\"mean,var:\",zmean1,zdisp1)\n",
    "if zdisp1 > 0:\n",
    "    sigma1 = math.sqrt(zdisp1)\n",
    "    print(\"sigma,FWHM:\",sigma1,sigma1*2.355)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [scipy](https://docs.scipy.org/doc/scipy/reference/) module has a large number of optimization and fitting routines that work with numpy arrays. They directly call lower level C routines, generally making fitting a fast process.\n",
    "\n",
    "To fit an actual gaussian , instead of using moments, we use the [curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit)\n",
    "function in [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def gauss(x, *p):\n",
    "    # if len(p) != 3: raise ValueError(\"Error, found %d, (%s), need 3\" % (len(p),str(p)))\n",
    "    A, mu, sigma = p\n",
    "    return A*np.exp(-(x-mu)**2/(2.*sigma**2)) \n",
    "\n",
    "# p0 is the initial guess for the fitting coefficients (A, mu and sigma above, in that order)\n",
    "# does it matter what the initial conditions are?\n",
    "p0 = [0.01, 10, 10]\n",
    "#p0 = [0.004, 24, 6]\n",
    "#p0 = [0.007, 100, 22, 0]\n",
    "\n",
    "coeff, cm = curve_fit(gauss, velz, flux, p0=p0)\n",
    "flux_fit = gauss(velz, *coeff)\n",
    "\n",
    "plt.plot(velz,flux,     label='Data')\n",
    "plt.plot(velz,flux_fit, label='Fit')\n",
    "plt.legend()\n",
    "\n",
    "print(\"Fitted amp            :\",coeff[0])\n",
    "print(\"Fitted mean           :\",coeff[1])\n",
    "print(\"Fitted sigma and FWHM :\",coeff[2], coeff[2]*2.355)\n",
    "print(\"Covariance Matrix     :\\n\",cm)\n",
    "# what are now the errors in the fitted values?\n",
    "print(\"error amp:\",math.sqrt(cm[0][0]))\n",
    "print(\"error mean:\",math.sqrt(cm[1][1]))\n",
    "print(\"error sigma:\",math.sqrt(cm[2][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Q1:  extend the gauss model to have a baseline that is not 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpecKit\n",
    "\n",
    "PySpecKit is an extensible spectroscopic analysis toolkit for astronomy. See\n",
    "http://pyspeckit.bitbucket.org/html/sphinx/index.html\n",
    "\n",
    "Installing this with\n",
    "```\n",
    "    pip install pyspeckit\n",
    "```\n",
    "resulted in an error \n",
    "```\n",
    "    AttributeError: module 'distutils.config' has no attribute 'ConfigParser'\n",
    "```\n",
    "turns out this was a python2/3 hack that was needed. The current released version of pyspeckit did not handle this. A manual install of the development release solved this, although a update to pip may be needed as well:\n",
    "```\n",
    "    pip install --upgrade pip\n",
    "    pip install https://bitbucket.org/pyspeckit/pyspeckit/get/master.tar.gz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modify to run\n",
    "\n",
    "The cell below is an adapted version of a gaussian fit case from the pySpecKit manual.  By default, this will create some known data with noise. Copy the cell and change it to make it work with our spectrum from n6503.  How does it compare to scipy's curve_fit ?   Note that in this method initial conditions are generated to help in a robust way of fitting the gauss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspeckit\n",
    "\n",
    "# set up a gauss (amp,center,sigma)\n",
    "xaxis = np.linspace(-50.0,150.0,100)\n",
    "amp = 1.0\n",
    "sigma = 10.0\n",
    "center = 50.0\n",
    "synth_data = amp*np.exp(-(xaxis-center)**2/(sigma**2 * 2.))\n",
    "\n",
    "# Add 10% noise (but fix the random seed)\n",
    "np.random.seed(123)\n",
    "stddev = 0.1\n",
    "noise = np.random.randn(xaxis.size)*stddev\n",
    "error = stddev*np.ones_like(synth_data)\n",
    "data = noise+synth_data\n",
    "\n",
    "# this will give a \"blank header\" warning, which is fine\n",
    "sp = pyspeckit.Spectrum(data=data, error=error, xarr=xaxis,\n",
    "                        xarrkwargs={'unit':'km/s'},\n",
    "                        unit='erg/s/cm^2/AA')\n",
    "\n",
    "sp.plotter()\n",
    "\n",
    "# Fit with automatic guesses\n",
    "sp.specfit(fittype='gaussian')\n",
    "\n",
    "# Fit with input guesses\n",
    "# The guesses initialize the fitter\n",
    "# This approach uses the 0th, 1st, and 2nd moments\n",
    "amplitude_guess = data.max()\n",
    "center_guess = (data*xaxis).sum()/data.sum()\n",
    "width_guess = data.sum() / amplitude_guess / np.sqrt(2*np.pi)\n",
    "guesses = [amplitude_guess, center_guess, width_guess]\n",
    "sp.specfit(fittype='gaussian', guesses=guesses)\n",
    "\n",
    "sp.plotter(errstyle='fill')\n",
    "sp.specfit.plot_fit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
