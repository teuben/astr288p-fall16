{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Line Data Cubes in Astronomy - Part 1 \n",
    "\n",
    "In this notebook we will introduce spectral line data cubes in astronomy. They are a convenient way to store many spectra at points in the sky. Much like having a spectrum at every pixel in a CCD. In this Part 1 we will keep it as much \"pure python\", and not use astronomical units and just work in \"pixel\" or \"voxel\" space.   In Part2 we will repeat the process with a more astronomy rich set of modules that you will have to install.\n",
    "\n",
    "They normally are presented as a [FITS](https://en.wikipedia.org/wiki/FITS) file, with two sky coordinates (often Right Ascension and Declination) and one spectral coordinate (either an observing frequency or wavelength, and when there is a known spectral line, you can reference using this line with a velocity using the doppler effect). For radio data, such as ALMA and the VLA, we often use GHz or MHz. For optical data we often use the Angstrom (the visible range is around 4000 - 8000 Angstrom).\n",
    "\n",
    "![Example Cube](../data/cube_dims_and_cell.png \"just an example cube\")\n",
    "## Outline\n",
    "\n",
    "**Main Goal:** To introduce the concepts of spectral line data cubes\n",
    "\n",
    "- Definition of image cube\n",
    "- Data representation image cube\n",
    "- Introduction to galaxy rotating disks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first line of code is actually not real python code, but a magic ipython command, to make sure that the standard plotting commands are going to be displayed within the browser. You will see that happen below. The cube figure about is just a static PNG file.\n",
    "\n",
    "As we will progress learning about the data and how to explore it further, you will notice this decision making process  throughout this notebook.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [astropy](http://www.astropy.org/) package has an I/O package to simplify reading and writing a number of popular formats common in astronomy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdu = fits.open('../data/ngc6503.cube.fits')\n",
    "print(len(hdu))\n",
    "print(hdu[0])\n",
    "print(hdu[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A FITS file consists of a series of Header-Data-Units (HDU). Usually there is only one, representing the image. But this file has two. For now, we're going to ignore the second, which is a special table and in this example happens to be empty anyways.  Each HDU has a header, and data.  The data in this case is a numpy array, and represents the image (cube):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = hdu[0].header\n",
    "d = hdu[0].data\n",
    "print(d.shape, d.min(), d.max(), d.mean(), np.median(d), d.std())\n",
    "print(\"Signal/Noise  (S/N):\",d.max()/d.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the shape (1,89,251,371) we can see this image is actually 4 dimensional, although the 4th dimension is dummy.  There are 371 pixels along X, 251 along Y, and 89 slices or spectral channels. It looks like the noise is around 0.00073 and a peak value 0.017, thus a signal to noise of a little over 23, so quite strong.\n",
    "\n",
    "In python you can remove that dummy 4th axis, since we are not going to use it any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = d.squeeze()\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you were wondering about that 4th redundant axis. In astronomy we sometimes observe more than one type of radiation. Since waves are polarized, we can have up to 4 so called Stokes parameters, describing the waves as e.g. linear or circular polarized radiation.  We will ignore that here, but they are sometimes stored in that 4th dimension. Sometimes they are stored as separate cubes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = 35\n",
    "im = d[z,:,:]#   im = d[z]     also works\n",
    "#im = d[z, 50:110, 210:270]\n",
    "#im = d[z, 100:150, 140:180]\n",
    "plt.imshow(im,origin=['Lower'])\n",
    "plt.colorbar()\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 89 channels (slices) in this cube, numbered 0 through 88 in the usual python sense. Pick a few other slices by changing the value in \n",
    "**z=** and notice that the first few and last few appear to be just noise and that the V-shaped signal changes shape through the channels. Perhaps you should not be surprised that these are referred to as butterfly diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at a histogram of all the data (histogram needs a 1D array)\n",
    "d1 = d.ravel()                 # ravel() doesn't make a new copy of the array, saving memory\n",
    "print(d1.shape)\n",
    "(n,b,p) = plt.hist(d1, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the histogram is on the left in the plot, and we already saw the maximum data point is 0.0169835.\n",
    "\n",
    "So let us plot the vertical axis logarithmically, so we can better see what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(n,b,p) = plt.hist(d1,bins=100,log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pick a slice and make a histogram and print the mean and standard deviation of the signal in that slice\n",
    "z=0\n",
    "imz = d[z,:,:].flatten()\n",
    "(n,b,p) = plt.hist(imz,bins=100)\n",
    "print(imz.mean(), imz.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** : observe by picking some values of **z** that the noise seems to vary a little bit from one end of the band to the other.  Store the noise in channel 0 and 88 in variables sigma0 and sigma88:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed the RMS in a channel, we might as well compute them for all channels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nchan = d.shape[0]\n",
    "channel = np.arange(nchan)\n",
    "rms = np.zeros(nchan)\n",
    "peak = np.zeros(nchan)\n",
    "cuberms = np.zeros(nchan) + d.std()\n",
    "for z in range(nchan):\n",
    "    imz = d[z,:,:].flatten()\n",
    "    rms[z] = imz.std()\n",
    "    peak[z] = imz.max()\n",
    "plt.plot(channel,rms,label='rms')\n",
    "#plt.plot(channel,peak,label='peak')\n",
    "plt.plot(channel,cuberms,label='cuberms')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Channel\")\n",
    "plt.ylabel(\"RMS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**  can you think of a better way to compute the RMS as function of channel (the blue line) and *not* have it depend so much on where there is signal?\n",
    "\n",
    "---\n",
    "\n",
    "Next we are interested in the Signal/Noise per channel where is there is no signal. This is clear in the first few and last channels. Recall that in the absence of real signal the peak will always be a few times sigma, purely based on the error function behavior of the distribution of gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sn0 = peak/rms[0:15].mean()\n",
    "sn1 = peak/rms[75:88].mean()\n",
    "plt.plot(channel,sn0,label='S/N(low)')\n",
    "plt.plot(channel,sn1,label='S/N(high)')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1=peak[0:15]/rms[0:15]\n",
    "s2=peak[75:88]/rms[75:88]\n",
    "print(\"First few channels:\",s1.mean(),s1.std())\n",
    "print(\"Last  few channels:\",s2.mean(),s2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian noise probability distribution is given by\n",
    "$$\n",
    "P(x) =  { 1 \\over {\\sigma \\sqrt{2\\pi}}} {e^{- { x^2 \\over {2 \\sigma^2}}}}\n",
    "$$\n",
    "where the mean is 0 and RMS is $\\sigma$.\n",
    "\n",
    "Lets do a simulation to see if we can understand the S/N in this plot. We will need the error function to compute the chance of being in the tail part of the gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pnoise(n):\n",
    "    \"\"\" chance measuring noise of n sigma\"\"\"\n",
    "    return 0.5*math.erfc(n/math.sqrt(2.0))\n",
    "\n",
    "nsample = 10000\n",
    "g = np.random.normal(size=nsample)\n",
    "sn = g.max()/g.std()\n",
    "print(\"S/N: \",sn)\n",
    "print(\"1/P(S/N)=\",1/pnoise(sn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1/chance for a +1,2,3 sigma detection\n",
    "print(1/pnoise(1.0))\n",
    "print(1/pnoise(2.0))\n",
    "print(1/pnoise(3.0))\n",
    "print(1/pnoise(4.3))\n",
    "nxy = d.shape[1]*d.shape[2]\n",
    "print(\"Number of pixels in a map:\",nxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peakpos = (175,125)    # some strong point in the disk of the galaxy\n",
    "#peakpos = (231,180)    # the mystery blob?\n",
    "#peakpos = (300,50)\n",
    "spectrum = d[:,peakpos[1],peakpos[0]]\n",
    "zero = spectrum * 0.0\n",
    "plt.plot(channel,spectrum,'o-',markersize=2)\n",
    "plt.plot(channel,zero)\n",
    "plt.plot(channel,cuberms,label='1$\\sigma$')\n",
    "plt.title(\"Spectrum at positon %s\" % str(peakpos))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### sigma0 = 0.00056\n",
    "sigma88 = 0.00059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import scipy.ndimage.filters as filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing a cube to enhance the signal to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = 0\n",
    "sigma = 2.0\n",
    "ds1 = filters.gaussian_filter(d[z],sigma)                    # ds1 is a single smoothed slice\n",
    "print(ds1.shape, ds1.mean(), ds1.std())\n",
    "plt.imshow(ds1,origin=['Lower'])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the noise is indeed lower than your earlier value of sigma0.   We only smoothed one single slice, but we actually need to smooth the whole cube.  Each slice  with sigma, but we can optionally also smooth in the spectral dimension a little bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = filters.gaussian_filter(d,[1.0,sigma,sigma])              # ds is a smoothed cube\n",
    "plt.imshow(ds[z],origin=['Lower'])\n",
    "plt.colorbar()\n",
    "print(ds.max(),ds.max()/ds1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, although the peak value was lowered a bit due to the smoothing, the signal to noise has increased from the original cube. So, the signal should stand out a lot better.\n",
    "\n",
    "**Exercise** : Observe a subtle difference in the last two plots. Can you see what happened here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  sigma0 is the noise in the original cube\n",
    "nsigma = 0.0\n",
    "dm = ma.masked_inside(d,-nsigma*sigma0,nsigma*sigma0)\n",
    "print(dm.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mom0 = dm.sum(axis=0)\n",
    "plt.imshow(mom0,origin=['Lower'])\n",
    "plt.colorbar()\n",
    "#\n",
    "(ypeak,xpeak) = np.unravel_index(mom0.argmax(),mom0.shape)\n",
    "print(\"PEAK at location:\",xpeak,ypeak,mom0.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spectrum2 = ds[:,ypeak,xpeak]\n",
    "plt.plot(channel,spectrum2)\n",
    "plt.plot(channel,zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mom0s = ds.sum(axis=0)\n",
    "plt.imshow(mom0s,origin=['Lower'])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Velocity fields\n",
    "\n",
    "The mean velocity is defined as the first moment\n",
    "\n",
    "$$\n",
    "<V> = {\\Sigma{(v.I)} \\over \\Sigma{(I)} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz = d.shape[0]\n",
    "vchan = np.arange(nz).reshape(nz,1,1)\n",
    "vsum = vchan * d\n",
    "vmean = vsum.sum(axis=0)/d.sum(axis=0)\n",
    "print(\"MINMAX\",vmean.min(),vmean.max())\n",
    "plt.imshow(vmean,origin=['Lower'],vmin=0,vmax=88)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we can recognize an area of coherent motions (the red and blue shifted sides of the galaxy), there is a lot of noise in this image. Looking at the math, we are dividing two numbers, both of which can be noise, so the outcome can be \"anything\".  If anything, it should be a value between 0 and 88, so we could mask for that and see how that looks.\n",
    "\n",
    "Let us first try to see how the smoothed cube looked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz = ds.shape[0]\n",
    "vchan = np.arange(nz).reshape(nz,1,1)\n",
    "vsum = vchan * ds\n",
    "vmean = vsum.sum(axis=0)/ds.sum(axis=0)\n",
    "print(vmean.shape,vmean.min(),vmean.max())\n",
    "plt.imshow(vmean,origin=['Lower'],vmin=0,vmax=89)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although more coherent, there are still bogus values outside the image of the galaxy. So we are looking for a hybrid of the two methods.  In the smooth cube we saw the signal to noise is a lot better defined, so we will define areas in the cube where the signal to noise is high enough and use those in the original high resolution cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is all messy , we need a better solution, a hybrid of the two:\n",
    "noise = ds[0:5].flatten()\n",
    "(n,b,p) = plt.hist(noise,bins=100)\n",
    "print(noise.mean(), noise.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma0 = noise.std()\n",
    "nsigma = 5.0\n",
    "cutoff = sigma0*nsigma\n",
    "dm = ma.masked_inside(ds,-cutoff,cutoff)\n",
    "print(cutoff,dm.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dm2=ma.masked_where(ma.getmask(dm),d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vsum = vchan * dm2\n",
    "vmean = vsum.sum(axis=0)/dm2.sum(axis=0)\n",
    "print(vmean.min(),vmean.max())\n",
    "plt.imshow(vmean,origin=['Lower'],vmin=0,vmax=89)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila, now this looks a lot better.\n",
    "\n",
    "## Papers\n",
    "\n",
    "The data cube we have used in this notebook has been provided by Eric Greisen (NRAO), and his 2009 paper discussed results in detail: \n",
    "http://adsabs.harvard.edu/abs/2009AJ....137.4718G\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epilogue\n",
    "\n",
    "Some of the pure python constructs that we discussed here, notably masking and smoothing, become cumbersome. In the advanced case we will use some community developed code that makes working with such spectral line image cubes a lot easier. Thing that come to mind are:\n",
    "* WCS (astronomical coordinate systems)\n",
    "* units (the flux unit in radio astronomy is Jy/beam)\n",
    "* arbitrary slices through the cube\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
